{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Challenge Nexialog**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objectif du projet\n",
    "<p style=\"text-align: justify;\">\n",
    "Des tests sont réalisés dans toutes les boxs, permettant d'identifier implicitement les interruptions de réseau.\n",
    "L'objectif est de mettre en place une approche non supervisé pour détecter des futurs problèmes sur une partie du réseau → Détection « d’anneaux ». Il faut détecter les noeuds du réseau qui sont défaillants en essayant d’anticiper le plus possible à l’avance.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/250203_tests_fixe_dns_sah_202412_202501.parquet', engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est une période de tests de 2 mois avec une fréquence par heure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "def afficher_pourcentage_valeurs_manquantes(df):\n",
    "    pourcentage_manquantes = round(df.isna().mean() * 100, 2)\n",
    "    pourcentage_manquantes = pourcentage_manquantes.sort_values(ascending=False)\n",
    "    print(\"Pourcentage de valeurs manquantes par variable (en %) :\\n\")\n",
    "    print(pourcentage_manquantes)\n",
    "\n",
    "afficher_pourcentage_valeurs_manquantes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing de la date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df['date_hour'] = pd.to_datetime(df['date_hour'])\n",
    "df['date_hour'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèles d'OLT :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df.olt_model.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observons les liens entre les différentes étapes du réseau**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OLT_PEAG_boucle'] = df['olt_name'] + df['peag_nro']  + df['boucle'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print('Nombre total de combinaisons OLT x PEAG x boucle :',df['OLT_PEAG_boucle'].nunique())\n",
    "print('Nombre de noms de OLT :', df.olt_name.nunique())\n",
    "print('Nombre de noms de PEAG :', df.peag_nro.nunique())\n",
    "print('Nombre de noms de boucle :', df.boucle.nunique())\n",
    "print('Nombre de noms de PEBIB :', df.pebib.nunique())\n",
    "print('Nombre de noms de DSP :', df.dsp.nunique())\n",
    "\n",
    "\n",
    "# print('Nombre de départements :', df.code_departement.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre d'associations de chaque noeud à l'autre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print('Nombre d\\'OLT par PEAG :', round(df.groupby('peag_nro')['olt_name'].nunique().mean(), 2))\n",
    "print('Nombre de PEAG par boucle :', round(df.groupby('boucle')['peag_nro'].nunique().mean(), 2))\n",
    "print('Nombre de boucle par PEBIB :', round(df.groupby('pebib')['boucle'].nunique().mean(), 2))\n",
    "print('Nombre de PEBIB par DSP :', round(df.groupby('dsp')['pebib'].nunique().mean(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de noeuds testés par heure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "exemple_date_list = [\n",
    "    '2024-12-30 23:00:00',\n",
    "    '2025-01-14 01:00:00',\n",
    "    '2025-01-01 10:00:00',\n",
    "    '2024-12-17 12:00:00',\n",
    "    '2024-12-12 07:00:00'\n",
    "]\n",
    "\n",
    "for date in exemple_date_list:\n",
    "    df_exemple = df[df['date_hour'] == date].copy()\n",
    "    print('Nombre de boucles testées le', date, ':')\n",
    "    print('Nombre de lignes pour cette date :', len(df_exemple))\n",
    "    print('Nombre total de boucles x PEAG x OLT :',df_exemple['OLT_PEAG_boucle'].nunique())\n",
    "    print('Nombre de noms de OLT :', df_exemple.olt_name.nunique())\n",
    "    print('Nombre de noms de PEAG :', df_exemple.peag_nro.nunique())\n",
    "    print('Nombre de noms de PEBIB :', df_exemple.pebib.nunique())\n",
    "    print('Nombre de noms de DSP :', df_exemple.dsp.nunique())\n",
    "    print('-'*5)\n",
    "    print('Nombre de départements :', df_exemple.code_departement.nunique())\n",
    "    print('-'*50)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obervons un seul OLT particulier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "olt_choisi = '01_olt_5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df_one_olt = df[df['olt_name'] == olt_choisi]\n",
    "print(df_one_olt.shape)\n",
    "print('Nombre d\\'heures :', df_one_olt['date_hour'].nunique())\n",
    "df_one_olt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24 h * 31 jours * 2 mois = 1488. Ici, on a 1632 lignes, observons pourquoi :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df_one_olt_duplicate = df_one_olt[df_one_olt['date_hour'].duplicated(keep=False)]\n",
    "print('Nombre de lignes qui ont été dupliquées :', len(df_one_olt_duplicate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observons les lignes qui sont dupliquées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df_one_olt_duplicate.sort_values(by='date_hour', inplace=True)\n",
    "df_one_olt_duplicate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela semble être des erreurs, le même test affiché plusieurs fois. Il faut donc les supprimer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df_one_olt = df_one_olt.drop_duplicates(subset='date_hour', keep='first')\n",
    "df_one_olt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualisations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajout de colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.renderers.default = 'notebook'\n",
    "col_palette=['#5533FF','#19A368','#521265','#751818',\"#FF5733\",'#5533FF','#19A368','#5533FF','#19A368', '#521265']\n",
    "col_to_plot = ['nb_test_dns', 'avg_dns_time', 'std_dns_time', 'nb_test_scoring', 'avg_latence_scoring',\n",
    "       'std_latence_scoring', 'avg_score_scoring', 'std_score_scoring', 'nb_client_total']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lineplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# visualisation d'un OLT\n",
    "for i, feature in enumerate(col_to_plot):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df_one_olt['date_hour'], df_one_olt[feature], label=feature, color=col_palette[i])\n",
    "    \n",
    "    plt.title(f\"{feature} - {olt_choisi}\")\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(feature)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut supposer que les pics dans les données de variables de test sont associées à des problèmes sur le réseau. Ce sont certainement des anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogrammes (Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Visualisation avec des histogrammes\n",
    "for i, feature in enumerate(col_to_plot):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.hist(df_one_olt[feature], bins=100, color=col_palette[i], alpha=0.7, label=feature)\n",
    "    \n",
    "\n",
    "    plt.title(f\"Distribution de {feature} - {olt_choisi}\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Fréquence')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs des queues de distribution sont certainement des anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sélection des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_distribution_single(df, label):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(df['count'], bins=30)\n",
    "    plt.title(f'Distribution of Counts - {label}')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "def select_the_data(df, seuil) :\n",
    "\n",
    "    \"\"\"  \n",
    "    Cette fonction récupère un DataFrame et un seuil en paramètre et retourne un nouveau DataFrame\n",
    "    contenant uniquement les combinaisons PEAG x OLT x PEBIB x boucle x code_departement sans duppliqués\n",
    "    \"\"\"\n",
    "    \n",
    "    initial_shape = df.shape\n",
    "    print(f'Shape du DF orginal : {initial_shape}')\n",
    "    cols_to_fix = ['avg_dns_time', 'std_dns_time', 'std_latence_scoring', 'std_score_scoring', 'avg_latence_scoring', 'avg_score_scoring'] \n",
    "    std_cols = ['std_dns_time', 'std_latence_scoring', 'std_score_scoring']\n",
    "    df[cols_to_fix] = df[cols_to_fix].round(3) # On arrondi car parfois 2 lignes parfaitement identiques vont différer seulement par \n",
    "    # quelques décimales, ce qui n'est pas détecté par la fonction drop_duplicates.\n",
    "    df['pebib'] = df['pebib'].fillna('pebib non defini')\n",
    "    \n",
    "    df = df.drop_duplicates()\n",
    "    df = df.drop_duplicates(subset=['date_hour','peag_nro', 'olt_name', 'pebib', 'boucle', 'code_departement', 'olt_model', 'dsp', 'pop_dns'], keep='first')\n",
    "\n",
    "    print(f'Shape du nouveau DF après avoir Drop tout les duplicates : {df.shape}')\n",
    "    print(f\"Cela correspond à une suppression de {initial_shape[0] - df.shape[0]} lignes\")\n",
    "\n",
    "\n",
    "    df['PEAG_OLT_PEBIB'] = df['peag_nro'].astype(str) + df['olt_name'].astype(str) + df['pebib'].astype(str) + df['boucle'].astype(str) + df['code_departement'].astype(str)\n",
    "    df_peag = df['PEAG_OLT_PEBIB'].value_counts().reset_index()\n",
    "    df_peag.columns = ['PEAG_OLT_PEBIB', 'count']\n",
    "    valid_values = df_peag[df_peag['count'] >= seuil]['PEAG_OLT_PEBIB'] # On sélectionne uniquement les combinaisons possédant plus de 100 valeurs\n",
    "    df = df[df['PEAG_OLT_PEBIB'].isin(valid_values)] # On garde uniquement les lignes correspondant à ces combinaisons dans notre DF\n",
    "\n",
    "    print(f'Shape du nouveau DF après avoir supprimé les combinaisons avec moins de {seuil} valeurs : {df.shape}')\n",
    "    print(f\"Cela correspond à une suppression de {initial_shape[0] - df.shape[0]} lignes\")\n",
    "\n",
    "    for col in std_cols:\n",
    "        df = df[df[col] != 0] # On supprime les lignes où la valeur de l'écart-type est égale à 0\n",
    "\n",
    "    print(f'Shape du nouveau DF : {df.shape}')\n",
    "    print(f\"Cela correspond à une suppression de {initial_shape[0] - df.shape[0]} lignes\")\n",
    "\n",
    "    return df\n",
    "\n",
    "new_df = select_the_data(df, 100)\n",
    "new_df_grouped = new_df.groupby('PEAG_OLT_PEBIB').size().reset_index(name='count').sort_values(by='count', ascending=False)\n",
    "new_df.to_csv(\"new_df.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "visualize_distribution_single(new_df_grouped, \"Distribution du nombre d'observation par combinaison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "new_df_grouped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

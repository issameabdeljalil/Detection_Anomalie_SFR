"""
Challenge Nexialog MoSEF
Interface Streamlit r√©organis√©e :
- Tableau de bord principal avec vue d'ensemble
- Configuration et lancement de la d√©tection d'anomalies
- Affichage des r√©sultats filtr√©s sur les anomalies avec leur m√©thode de d√©tection
- Insertion optionnelle d'anomalies dans des noeuds choisis (Boucles, PEAG, OLT)
- Visualisation 3D des anomalies (approche unidimensionnelle ou multidimensionnelle)
"""

import streamlit as st
import numpy as np
import pandas as pd
from scipy.stats import gaussian_kde
import plotly.graph_objects as go
from plotly.subplots import make_subplots

from utils import import_json_to_dict
from nodes_checker import NodesChecker
from anomaly_detection_isolation_forest import MultiIsolationForestDetector

# Configuration 
st.set_page_config(
    page_title="Challenge Nexialog - D√©tection d'anomalies",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded",
)

def initialize_session_state():
    if "donnees_chargees" not in st.session_state:
        # Importation de l'heure simul√©e
        # st.session_state.lignes_1fev = pd.read_csv('data/results/lignes_1fev.csv', index_col=0).replace([np.inf, -np.inf], np.nan).dropna().head(300)
        st.session_state.lignes_1fev = pd.read_csv('data/results/lignes_1fev.csv', index_col=0).replace([np.inf, -np.inf], np.nan).dropna()
        st.session_state.lignes_1fev_copy = st.session_state.lignes_1fev.copy()
        # Importation des vecteurs de distribution par test
        st.session_state.dict_distribution_test = import_json_to_dict("data/results/dict_test.json")
        # Colonnes dans lesquelles injecter et rep√©rer des anomalies
        st.session_state.variables_test = [
            'avg_score_scoring',
            'avg_latence_scoring',
            'avg_dns_time',
            'std_score_scoring',
            'std_latence_scoring',
            'std_dns_time'
        ]
        
        st.session_state.df_with_anomalies = None

        # Nouvelles colonnes de p_values √† ajouter
        st.session_state.p_values_col = [
            'p_val_avg_dns_time',
            'p_val_avg_score_scoring',
            'p_val_avg_latence_scoring',
            'p_val_std_dns_time',
            'p_val_std_score_scoring',
            'p_val_std_latence_scoring'
        ]

        st.session_state.p_value_threshold = 5.0  # Seuil de sensibilit√©/rejet
        st.session_state.donnees_chargees = True
        
        # Initialisation du d√©tecteur Isolation Forest
        st.session_state.isolation_forest = MultiIsolationForestDetector(chain_id_col = 'name')
        # chargement des modeles d'isolation forest
        st.session_state.isolation_forest.load_models(st.session_state.lignes_1fev_copy)

        st.session_state.isolation_forest_threshold = 0.00
        
        # Variables pour stocker les r√©sultats des analyses
        st.session_state.results = {
            "boucles": None,
            "peag_nro": None,
            "olt": None
        }
       
        st.session_state.anomalies_detected = False

# Fonction pour afficher l'en-t√™te de l'application
def show_header():
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col1:
        st.image("images/SFR_logo.png", width=120, use_container_width=False)
    
    with col2:
        st.title("D√©tection d'anomalies sur le r√©seau")
        st.caption("Challenge Nexialog & Universit√© Paris 1 Panth√©on-Sorbonne")
    
    with col3:
        st.image("images/nexialog_logo.png", width=120, use_container_width=False)
    
    # CSS pour l'alignement
    st.markdown("""
    <style>
    [data-testid="stHorizontalBlock"] {
        align-items: center;
    }
    [data-testid="stHorizontalBlock"] > div:first-child {
        display: flex;
        justify-content: flex-start;
        align-items: center;
        padding-left: 10px;
    }
    [data-testid="stHorizontalBlock"] > div:last-child {
        display: flex;
        justify-content: flex-end;
        align-items: center;
        padding-right: 10px;
    }
    [data-testid="stHorizontalBlock"] > div:nth-child(2) {
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
    }
    </style>
    """, unsafe_allow_html=True)
    
    st.markdown("---")

# Page tableau de bord
def show_home():
    st.header("üìä Tableau de bord")
    
    # Section KPIs principaux
    st.subheader("Indicateurs cl√©s de performance")
    
    # Premi√®re ligne - Statistiques g√©n√©rales et m√©triques r√©seau
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric(label="Nombre de cha√Ænes techniques", 
                 value=len(st.session_state.lignes_1fev['name'].unique()))
    
    # Calcul des temps moyens DNS et latence
    avg_dns = st.session_state.lignes_1fev['avg_dns_time'].mean()
    avg_latence = st.session_state.lignes_1fev['avg_latence_scoring'].mean()
    
    with col2:
        st.metric(label="Temps DNS moyen (ms)", 
                  value=f"{avg_dns:.2f}")
    with col3:
        st.metric(label="Latence scoring moyenne (ms)", 
                  value=f"{avg_latence:.2f}")
    
    # Deuxi√®me ligne - Indicateurs de sant√© r√©seau
    st.subheader("Sant√© du r√©seau")
    
    # Calcul des indicateurs de variabilit√©
    col1, col2, col3 = st.columns(3)
    with col1:
        # Calcul de la stabilit√© DNS (bas√© sur std_dns_time)
        std_dns = st.session_state.lignes_1fev['std_dns_time'].mean()
        dns_stability = 100 - min(100, (std_dns / avg_dns * 100))
        st.metric(label="Stabilit√© DNS (%)", 
                  value=f"{dns_stability:.1f}")
    
    with col2:
        # Calcul de la qualit√© scoring (bas√© sur avg_score_scoring)
        avg_score = st.session_state.lignes_1fev['avg_score_scoring'].mean()
        score_quality = min(100, (avg_score / 5) * 100)  # Supposant que le score max est 5
        st.metric(label="Qualit√© scoring (%)", 
                  value=f"{score_quality:.1f}")
    
    with col3:
        # Calcul de la stabilit√© latence
        std_latence = st.session_state.lignes_1fev['std_latence_scoring'].mean()
        latence_stability = 100 - min(100, (std_latence / avg_latence * 100))
        st.metric(label="Stabilit√© latence (%)", 
                  value=f"{latence_stability:.1f}")
    
    # Troisi√®me ligne - Visualisation de la distribution
    st.subheader("Distribution des m√©triques cl√©s")
    
    # Cr√©er un histogramme pour visualiser les distributions
    fig = create_metrics_distribution()
    st.plotly_chart(fig, use_container_width=True)
    
    # Mini ReadMe sur le projet
    st.markdown("---")
    st.subheader("√Ä propos de l'application")
    st.write("""
    Cette application de d√©tection d'anomalies permet de:
    
    - **Configurer et lancer** la d√©tection d'anomalies avec deux approches compl√©mentaires
    - **Visualiser** les r√©sultats et comprendre les anomalies d√©tect√©es
    - **Simuler** (optionnellement) l'injection d'anomalies dans diff√©rentes parties du r√©seau
    
    Utilisez le menu ci-dessus pour naviguer entre les diff√©rentes fonctionnalit√©s.
    """)

# Fonction pour cr√©er les visualisations de distribution des m√©triques
def create_metrics_distribution():
    
    # Cr√©er un subplot avec 3 graphiques
    fig = make_subplots(rows=1, cols=3, 
                        subplot_titles=("Distribution des temps DNS", 
                                        "Distribution des scores", 
                                        "Distribution des latences"))
    
    # Histogramme pour les temps DNS
    fig.add_trace(
        go.Histogram(
            x=st.session_state.lignes_1fev['avg_dns_time'],
            name="Temps DNS",
            marker_color='#1f77b4',
            opacity=0.7
        ),
        row=1, col=1
    )
    
    # Histogramme pour les scores
    fig.add_trace(
        go.Histogram(
            x=st.session_state.lignes_1fev['avg_score_scoring'],
            name="Scores",
            marker_color='#2ca02c',
            opacity=0.7
        ),
        row=1, col=2
    )
    
    # Histogramme pour les latences
    fig.add_trace(
        go.Histogram(
            x=st.session_state.lignes_1fev['avg_latence_scoring'],
            name="Latences",
            marker_color='#d62728',
            opacity=0.7
        ),
        row=1, col=3
    )
    
    # Mise √† jour de la mise en page
    fig.update_layout(
        height=300,
        bargap=0.1,
        showlegend=False
    )
    
    return fig

# Page de configuration et d√©tection
def show_detection_config():
    st.header("‚öôÔ∏è Configuration et lancement de la d√©tection d'anomalies")
  
    # Configuration du seuil selon la m√©thode
    st.subheader("Configuration des seuils")
    
    new_threshold = st.slider(
        "Seuil (%) de rejet Œ± pour la d√©tection d'anomalies unidimensionnelle", 
        min_value=0.0, 
        max_value=20.0, 
        value=st.session_state.p_value_threshold, 
        step=0.05,
        format="%.1f"
    )
    st.session_state.p_value_threshold = new_threshold
    st.info(f"Les variables avec une p-value inf√©rieure √† {new_threshold}% seront consid√©r√©es comme anormales")
    
    new_threshold = st.slider(
        "Seuil de la moyenne des scores d'Isolation Forest pour la d√©tection multidimensionnelle", 
        min_value=-1.0, 
        max_value=0.5, 
        value=st.session_state.isolation_forest_threshold, 
        step=0.05,
        format="%.2f"
    )
    st.session_state.isolation_forest_threshold = new_threshold
    st.info(f"Les n≈ìuds avec une moyenne de scores d'anomalies inf√©rieure √† {new_threshold} seront consid√©r√©s comme anormaux")
    
    # Lancement de la d√©tection
    st.markdown("---")
    launch_button_text = "üöÄ Lancer la d√©tection d'anomalies"
    
    if st.button(launch_button_text, type="primary"):
        with st.spinner("D√©tection d'anomalies en cours ..."):
            run_anomaly_detection()
            st.session_state.anomalies_detected = True
            st.success("D√©tection d'anomalies termin√©e avec succ√®s!")
            st.balloons()  # Animation pour c√©l√©brer la fin de l'analyse

# Page des r√©sultats
def show_results():
    st.header("üìà R√©sultats de la d√©tection d'anomalies")
    
    if not st.session_state.anomalies_detected:
        st.warning("Aucune d√©tection d'anomalies n'a √©t√© lanc√©e. Veuillez configurer et lancer une d√©tection d'abord.")
        return
    
    # Afficher d'abord le r√©sum√© des anomalies d√©tect√©es
    st.subheader("R√©sum√© des anomalies d√©tect√©es")
    display_anomaly_summary()
    
    # # Afficher les visualisations des anomalies par type de n≈ìud
    # st.markdown("---")
    # st.subheader("Distribution des anomalies")
    # display_node_anomaly_chart()
    
    # Cr√©ation d'onglets pour les diff√©rents types de r√©sultats
    tab1, tab2, tab3, tab4 = st.tabs(["Boucles", "PEAG", "OLT", "Visualisation 3D"])
    
    results = st.session_state.results
    threshold_p_val = st.session_state.p_value_threshold / 100
    threshold_if = st.session_state.isolation_forest_threshold
    
    with tab1:
        st.subheader("Boucles anormales")
        if results["boucles"] is not None:
            # Filtrer seulement les boucles anormales - utiliser uniquement 3 p-values principales
            df = results["boucles"].copy()
            # N'utiliser que les 3 p-values principales (moyennes) pour √™tre coh√©rent avec le r√©sum√©
            main_p_values = ['p_val_avg_dns_time', 'p_val_avg_score_scoring', 'p_val_avg_latence_scoring']
            p_val_min = df[main_p_values].min(axis=1)
            mask_p_val = p_val_min < threshold_p_val
            mask_if = df['avg_isolation_forest_score'] < threshold_if
            filtered_df = df[mask_p_val | mask_if].sort_values(by="avg_isolation_forest_score")
            
            # Ajouter une colonne indiquant la m√©thode de d√©tection
            filtered_df['m√©thode_d√©tection'] = ''
            filtered_df.loc[mask_p_val & mask_if, 'm√©thode_d√©tection'] = 'Les deux m√©thodes'
            filtered_df.loc[mask_p_val & ~mask_if, 'm√©thode_d√©tection'] = 'Unidimensionnelle'
            filtered_df.loc[~mask_p_val & mask_if, 'm√©thode_d√©tection'] = 'Isolation Forest'

            if filtered_df.empty:
                st.info("Aucune boucle anormale n'a √©t√© d√©tect√©e avec les seuils actuels.")
            else:
                st.write(f"Nombre de boucles anormales d√©tect√©es: {len(filtered_df)} sur {len(df)}.")
                
                # Fonction pour colorer les cellules
                def color_cells(val, idx, col_name):
                    if col_name in st.session_state.p_values_col and val < threshold_p_val:
                        return 'background-color: #ffcccc'
                    elif col_name == 'avg_isolation_forest_score' and val < threshold_if:
                        return 'background-color: #ffcccc'
                    return ''
                
                # Appliquer la coloration
                styled_df = filtered_df.style.apply(lambda row: [
                    color_cells(row[col], row.name, col) for col in filtered_df.columns
                ], axis=1)
                
                st.dataframe(styled_df)
    
    with tab2:
        st.subheader("PEAG anormaux")
        if results["peag_nro"] is not None:
            # Filtrer seulement les PEAG anormaux - utiliser uniquement 3 p-values principales
            df = results["peag_nro"].copy()
            # N'utiliser que les 3 p-values principales (moyennes) pour √™tre coh√©rent avec le r√©sum√©
            main_p_values = ['p_val_avg_dns_time', 'p_val_avg_score_scoring', 'p_val_avg_latence_scoring']
            p_val_min = df[main_p_values].min(axis=1)
            mask_p_val = p_val_min < threshold_p_val
            mask_if = df['avg_isolation_forest_score'] < threshold_if
            filtered_df = df[mask_p_val | mask_if].sort_values(by="avg_isolation_forest_score")
            
            # Ajouter une colonne indiquant la m√©thode de d√©tection
            filtered_df['m√©thode_d√©tection'] = ''
            filtered_df.loc[mask_p_val & mask_if, 'm√©thode_d√©tection'] = 'Les deux m√©thodes'
            filtered_df.loc[mask_p_val & ~mask_if, 'm√©thode_d√©tection'] = 'Unidimensionnelle'
            filtered_df.loc[~mask_p_val & mask_if, 'm√©thode_d√©tection'] = 'Isolation Forest'
            
            if filtered_df.empty:
                st.info("Aucun PEAG anormal n'a √©t√© d√©tect√© avec les seuils actuels.")
            else:
                st.write(f"Nombre de PEAG anormaux d√©tect√©s: {len(filtered_df)} sur {len(df)}.")
                
                # Fonction pour colorer les cellules
                def color_cells(val, idx, col_name):
                    if col_name in st.session_state.p_values_col and val < threshold_p_val:
                        return 'background-color: #ffcccc'
                    elif col_name == 'avg_isolation_forest_score' and val < threshold_if:
                        return 'background-color: #ffcccc'
                    return ''
                
                # Appliquer la coloration
                styled_df = filtered_df.style.apply(lambda row: [
                    color_cells(row[col], row.name, col) for col in filtered_df.columns
                ], axis=1)
                
                st.dataframe(styled_df)
    
    with tab3:
        st.subheader("OLT anormaux")
        if results["olt"] is not None:
            # Filtrer seulement les OLT anormaux - utiliser uniquement 3 p-values principales
            df = results["olt"].copy()
            # N'utiliser que les 3 p-values principales (moyennes) pour √™tre coh√©rent avec le r√©sum√©
            main_p_values = ['p_val_avg_dns_time', 'p_val_avg_score_scoring', 'p_val_avg_latence_scoring']
            p_val_min = df[main_p_values].min(axis=1)
            mask_p_val = p_val_min < threshold_p_val
            mask_if = df['avg_isolation_forest_score'] < threshold_if
            filtered_df = df[mask_p_val | mask_if].sort_values(by="avg_isolation_forest_score")
            
            # Ajouter une colonne indiquant la m√©thode de d√©tection
            filtered_df['m√©thode_d√©tection'] = ''
            filtered_df.loc[mask_p_val & mask_if, 'm√©thode_d√©tection'] = 'Les deux m√©thodes'
            filtered_df.loc[mask_p_val & ~mask_if, 'm√©thode_d√©tection'] = 'Unidimensionnelle'
            filtered_df.loc[~mask_p_val & mask_if, 'm√©thode_d√©tection'] = 'Isolation Forest'
            
            if filtered_df.empty:
                st.info("Aucun OLT anormal n'a √©t√© d√©tect√© avec les seuils actuels.")
            else:
                st.write(f"Nombre d'OLT anormaux d√©tect√©s: {len(filtered_df)} sur {len(df)}.")
                
                # Fonction pour colorer les cellules
                def color_cells(val, idx, col_name):
                    if col_name in st.session_state.p_values_col and val < threshold_p_val:
                        return 'background-color: #ffcccc'
                    elif col_name == 'avg_isolation_forest_score' and val < threshold_if:
                        return 'background-color: #ffcccc'
                    return ''
                
                # Appliquer la coloration
                styled_df = filtered_df.style.apply(lambda row: [
                    color_cells(row[col], row.name, col) for col in filtered_df.columns
                ], axis=1)
                
                st.dataframe(styled_df)
    
    with tab4:
        st.subheader("Visualisation 3D")
        
        col_test_names, col_test_vars = st.columns([1, 2])
        
        with col_test_names:
            test_name = st.selectbox(
                "Choix de la cha√Æne technique",
                options=sorted(list(st.session_state.lignes_1fev_copy['name'].unique()))
            )
        with col_test_vars:
            variables_test = st.multiselect(
                "Variables de test (s√©lectionnez exactement 2)",
                options=st.session_state.variables_test
            )
        
        if len(variables_test) != 2:
            st.error("Veuillez s√©lectionner exactement 2 variables de test √† repr√©senter en 3D")
        else:
            # Cr√©er et afficher le graphique 3D unidimensionnel
            try:
                fig = create_3d_plot(test_name, variables_test)
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"Erreur lors de la cr√©ation du graphique 3D : {str(e)}")

# Page d'insertion d'anomalies (optionnelle)
def show_anomaly_insertion():
    st.header("üîß Insertion d'anomalies (Optionnel)")
    
    st.info("""
    Cette section vous permet d'ins√©rer des anomalies simul√©es dans le r√©seau pour tester le syst√®me de d√©tection.
    Cette √©tape est optionnelle - si vous travaillez avec des donn√©es r√©elles, vous pouvez ignorer cette section.
    """)
    
    # Cr√©ation de tabs pour organiser l'insertion par type de n≈ìud
    tab1, tab2, tab3 = st.tabs(["Boucles", "PEAG", "OLT"])
    
    with tab1:
        st.subheader("Insertion d'anomalies dans les Boucles")
        col_names, col_vars, col_val, col_btn = st.columns([2, 2, 1, 1])
        
        with col_names:
            boucle_names = st.multiselect(
                "Boucles √† modifier", 
                options=sorted(list(st.session_state.lignes_1fev['boucle'].unique()))
            )
        with col_vars:
            var_test = st.multiselect(
                "Variables de test", 
                options=st.session_state.variables_test, 
                key='insertvar1'
            )
        with col_val:
            valeur_insertion = st.number_input(
                "Valeur √† ins√©rer", 
                value=0.0, 
                step=1.0, 
                key='insertion1'
            )
        with col_btn:
            if st.button("Ins√©rer anomalies", key="btn_inserer1"):
                st.write(f"Insertion d'une valeur de {round(valeur_insertion, 2)} dans {var_test} pour {len(boucle_names)} boucles")
                st.session_state.lignes_1fev = NodesChecker.add_anomalies(
                    st.session_state.lignes_1fev, 
                    'boucle', 
                    boucle_names,
                    var_test,
                    valeur_insertion
                )
                st.success(f"Anomalies ins√©r√©es avec succ√®s dans {len(boucle_names)} boucles!")
                # R√©initialiser le statut de d√©tection
                st.session_state.anomalies_detected = False
    
    with tab2:
        st.subheader("Insertion d'anomalies dans les PEAG")
        col_names, col_vars, col_val, col_btn = st.columns([2, 2, 1, 1])
        
        with col_names:
            peag_names = st.multiselect(
                "PEAG √† modifier", 
                options=sorted(list(st.session_state.lignes_1fev['peag_nro'].unique()))
            )
        with col_vars:
            var_test = st.multiselect(
                "Variables de test", 
                options=st.session_state.variables_test, 
                key='insertvar2'
            )
        with col_val:
            valeur_insertion = st.number_input(
                "Valeur √† ins√©rer", 
                value=0.0, 
                step=1.0, 
                key='insertion2'
            )
        with col_btn:
            if st.button("Ins√©rer anomalies", key="btn_inserer2"):
                st.write(f"Insertion d'une valeur de {round(valeur_insertion, 2)} dans {var_test} pour {len(peag_names)} PEAG")
                st.session_state.lignes_1fev = NodesChecker.add_anomalies(
                    st.session_state.lignes_1fev, 
                    'peag_nro', 
                    peag_names,
                    var_test,
                    valeur_insertion
                )
                st.success(f"Anomalies ins√©r√©es avec succ√®s dans {len(peag_names)} PEAG!")
                # R√©initialiser le statut de d√©tection
                st.session_state.anomalies_detected = False
    
    with tab3:
        st.subheader("Insertion d'anomalies dans les OLT")
        col_names, col_vars, col_val, col_btn = st.columns([2, 2, 1, 1])
        
        with col_names:
            olt_names = st.multiselect(
                "OLT √† modifier", 
                options=sorted(list(st.session_state.lignes_1fev['olt_name'].unique()))
            )
        with col_vars:
            var_test = st.multiselect(
                "Variables de test", 
                options=st.session_state.variables_test, 
                key='insertvar3'
            )
        with col_val:
            valeur_insertion = st.number_input(
                "Valeur √† ins√©rer", 
                value=0.0, 
                step=1.0, 
                key='insertion3'
            )
        with col_btn:
            if st.button("Ins√©rer anomalies", key="btn_inserer3"):
                st.write(f"Insertion d'une valeur de {round(valeur_insertion, 2)} dans {var_test} pour {len(olt_names)} OLT")
                st.session_state.lignes_1fev = NodesChecker.add_anomalies(
                    st.session_state.lignes_1fev, 
                    'olt_name', 
                    olt_names,
                    var_test,
                    valeur_insertion
                )
                st.success(f"Anomalies ins√©r√©es avec succ√®s dans {len(olt_names)} OLT!")
                # R√©initialiser le statut de d√©tection
                st.session_state.anomalies_detected = False
    
    # Bouton pour r√©initialiser les donn√©es
    st.markdown("---")
    if st.button("üîÑ R√©initialiser toutes les donn√©es", type="secondary"):
        st.session_state.lignes_1fev = st.session_state.lignes_1fev_copy.copy()
        st.session_state.anomalies_detected = False
        st.success("Toutes les donn√©es ont √©t√© r√©initialis√©es avec succ√®s!")

# Page d'aide
def show_help():
    st.header("‚ùì Aide et documentation")
    
    st.write("""
    ## Guide d'utilisation de l'application
    
    Cette application permet de d√©tecter des anomalies dans un r√©seau de t√©l√©communications en utilisant deux approches compl√©mentaires:
    
    1. **Approche unidimensionnelle** : Analyse chaque dimension s√©par√©ment avec des techniques de filtrage Hodrick-Prescott,
       de r√©duction des valeurs aberrantes, et d'estimation par noyau (KDE).
       
    2. **Isolation Forest** : Approche multidimensionnelle qui d√©tecte les anomalies en isolant les observations
       qui s'√©cartent du comportement habituel.
    
    ### Comment utiliser l'application
    
    1. **Tableau de bord** : Visualise l'√©tat actuel du r√©seau et donne un aper√ßu g√©n√©ral des m√©triques.
    
    2. **Configuration et d√©tection** : Permet de configurer les seuils de d√©tection et de lancer l'analyse.
       
    3. **R√©sultats** : Affiche le r√©sum√© des anomalies et les d√©tails par type de n≈ìud (Boucles, PEAG, OLT).
    
    4. **Insertion d'anomalies (Optionnel)** : Permet de simuler des anomalies dans le r√©seau pour tester le syst√®me.
       
    5. **Aide** : Documentation sur l'utilisation de l'application.
    
    ### Glossaire
    
    - **OLT** : Optical Line Terminal, √©quipement central du r√©seau fibre optique
    - **PEAG** : Point d'Entr√©e d'Acc√®s Goulte, point de raccordement interm√©diaire
    - **Boucle** : Segment du r√©seau reliant plusieurs points d'acc√®s
    - **p-value** : Probabilit√© d'observer une valeur au moins aussi extr√™me que celle observ√©e
    """)
    
    # FAQ
    st.subheader("Questions fr√©quentes")
    
    with st.expander("Comment fonctionne la d√©tection d'anomalies ?"):
        st.write("""
        L'application utilise deux approches compl√©mentaires :
        
        - **Approche unidimensionnelle** : Pour chaque m√©trique (DNS, scoring, latence), nous calculons une distribution de r√©f√©rence avec le filtre Hodrick-Prescott et une estimation par noyau (KDE). Nous comparons ensuite les nouvelles observations √† cette distribution pour calculer des p-values. Une p-value faible indique une anomalie.
        
        - **Isolation Forest** : Cette m√©thode multidimensionnelle consid√®re toutes les m√©triques ensemble. Elle isole les observations anormales en cr√©ant des partitions al√©atoires de l'espace. Les observations qui sont facilement isol√©es (moins de partitions n√©cessaires) sont consid√©r√©es comme des anomalies.
        """)
    
    with st.expander("Comment interpr√©ter les r√©sultats ?"):
        st.write("""
        - **p-values** : Plus elles sont basses, plus l'anomalie est significative. Une valeur inf√©rieure au seuil Œ± (par d√©faut 5%) indique une anomalie.
        
        - **Score d'Isolation Forest** : Les valeurs n√©gatives indiquent des anomalies. Plus le score est n√©gatif, plus l'anomalie est significative.
        
        - **M√©thode de d√©tection** : Indique quelle approche a d√©tect√© l'anomalie (unidimensionnelle, Isolation Forest, ou les deux).
        """)
    
    with st.expander("Comment simuler des anomalies ?"):
        st.write("""
        1. Allez dans la section "Insertion d'anomalies"
        2. S√©lectionnez le type de n≈ìud (Boucle, PEAG ou OLT)
        3. Choisissez les n≈ìuds sp√©cifiques √† modifier
        4. S√©lectionnez les variables de test √† modifier
        5. Entrez la valeur √† ajouter (une valeur √©lev√©e, comme 10 ou plus, cr√©era une anomalie √©vidente)
        6. Cliquez sur "Ins√©rer anomalies"
        7. Retournez √† "Configuration et d√©tection" pour lancer l'analyse
        """)

# Fonction pour afficher le r√©sum√© des anomalies
def display_anomaly_summary():
    results = st.session_state.results
    # D√©finir les seuils
    threshold_p_val = st.session_state.p_value_threshold / 100
    threshold_if = st.session_state.isolation_forest_threshold
    
    # Cr√©er deux colonnes principales
    col1, col2 = st.columns(2)
    
    # Fonction pour cr√©er une jauge d'anomalies
    def create_gauge_chart(percentage, title):
        fig = go.Figure(go.Indicator(
            mode="gauge+number",
            value=percentage,
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': title},
            gauge={
                'axis': {
                    'range': [0, 100],
                    'tickwidth': 1,
                    'tickcolor': "darkblue",
                    'tickvals': [0, 25, 50, 75, 100],
                    'ticktext': ['0', '25', '50', '75', '100'],
                    'tickangle': 0,
                    'tickfont': {'size': 12}
                },
                'bar': {'color': "darkblue"},
                'bgcolor': "white",
                'borderwidth': 2,
                'bordercolor': "gray",
                'steps': [
                    {'range': [0, 25], 'color': 'green'},
                    {'range': [25, 50], 'color': 'yellow'},
                    {'range': [50, 75], 'color': 'orange'},
                    {'range': [75, 100], 'color': 'red'}
                ],
            }
        ))
        
        fig.update_layout(
            height=200,
            width=320,
            margin=dict(l=20, r=50, t=50, b=20),
            paper_bgcolor="rgba(0,0,0,0)",
            plot_bgcolor="rgba(0,0,0,0)"
        )
        return fig
    
    with col1:
        if results["peag_nro"] is not None:
            
            df = results["peag_nro"]
            p_val_min = df[['p_val_avg_dns_time', 'p_val_avg_score_scoring', 'p_val_avg_latence_scoring']].min(axis=1)
            condition = (p_val_min < threshold_p_val) | (df['avg_isolation_forest_score'] < threshold_if)
            anomalous_peag = df[condition]
            
            # Pourcentage de PEAG anormaux
            peag_percent = round(100 * len(anomalous_peag) / len(results["peag_nro"]), 2)
            
            # Afficher la jauge
            st.plotly_chart(create_gauge_chart(peag_percent, f"% de PEAG anormaux"), use_container_width=True)
            
            st.metric("Nbr PEAG anormaux / Total", f"{len(anomalous_peag)} / {len(results['peag_nro'])}")

            if not anomalous_peag.empty:
                # Trouver les PEAG les plus probl√©matiques
                worst_peag = anomalous_peag.sort_values('avg_isolation_forest_score').index[:3]
                
                # Cr√©er une table avec formatage color√© pour les PEAG les plus anormaux
                st.markdown("#### PEAG les plus anormaux:")
                for idx in worst_peag:
                    score = anomalous_peag.loc[idx, 'avg_isolation_forest_score']
                    color = 'red' if score < threshold_if else 'orange'
                    st.markdown(f"<span style='color:{color};font-weight:bold;font-size:16px'>‚Ä¢ {idx}</span> (score: {score:.3f})", unsafe_allow_html=True)
    
    with col2:
        if results["olt"] is not None:
            df = results["olt"]
            p_val_min = df[['p_val_avg_dns_time', 'p_val_avg_score_scoring', 'p_val_avg_latence_scoring']].min(axis=1)
            condition = (p_val_min < threshold_p_val) | (df['avg_isolation_forest_score'] < threshold_if)
            anomalous_olt = df[condition]
            
            # Pourcentage d'OLT anormaux
            olt_percent = round(100 * len(anomalous_olt) / len(results["olt"]), 2)
            
            # Afficher la jauge
            st.plotly_chart(create_gauge_chart(olt_percent, f"% d'OLT anormaux"), use_container_width=True)
            
            st.metric("Nbr OLT anormaux / Total", f"{len(anomalous_olt)} / {len(results['olt'])}")
            
            if not anomalous_olt.empty:
                # Trouver les OLT les plus probl√©matiques
                worst_olt = anomalous_olt.sort_values('avg_isolation_forest_score').index[:3]
                
                # Cr√©er une table avec formatage color√© pour les OLT les plus anormaux
                st.markdown("#### OLT les plus anormaux:")
                for idx in worst_olt:
                    score = anomalous_olt.loc[idx, 'avg_isolation_forest_score']
                    color = 'red' if score < threshold_if else 'orange'
                    st.markdown(f"<span style='color:{color};font-weight:bold;font-size:16px'>‚Ä¢ {idx}</span> (score: {score:.3f})", unsafe_allow_html=True)

# # Fonction pour afficher le graphique des anomalies par type de n≈ìud
# def display_node_anomaly_chart():
#     """
#     Cr√©e un graphique de synth√®se montrant la distribution des anomalies par type de n≈ìud
#     et leur r√©partition par variable.
#     """
#     if not st.session_state.anomalies_detected:
#         return
    
#     # Cr√©er deux colonnes pour les graphiques
#     col1, col2 = st.columns(2)
    
#     with col1:
#         # Cr√©er un diagramme √† barres pour comparer les proportions d'anomalies par type de n≈ìud
#         node_types = ['PEAG', 'OLT']
#         anomaly_percentages = []

#         if st.session_state.results["peag_nro"] is not None:
#             df = st.session_state.results["peag_nro"]
#             p_val_min = df[['p_val_avg_dns_time', 'p_val_avg_score_scoring', 'p_val_avg_latence_scoring']].min(axis=1)
#             condition = (p_val_min < st.session_state.p_value_threshold / 100) | (df['avg_isolation_forest_score'] < st.session_state.isolation_forest_threshold)
#             anomaly_percentages.append(round(100 * sum(condition) / len(df), 2))
#         else:
#             anomaly_percentages.append(0)
        
#         if st.session_state.results["olt"] is not None:
#             df = st.session_state.results["olt"]
#             p_val_min = df[['p_val_avg_dns_time', 'p_val_avg_score_scoring', 'p_val_avg_latence_scoring']].min(axis=1)
#             condition = (p_val_min < st.session_state.p_value_threshold / 100) | (df['avg_isolation_forest_score'] < st.session_state.isolation_forest_threshold)
#             anomaly_percentages.append(round(100 * sum(condition) / len(df), 2))
#         else:
#             anomaly_percentages.append(0)
        
#         fig = go.Figure([
#             go.Bar(
#                 x=node_types,
#                 y=anomaly_percentages,
#                 marker_color=['#66B3FF', '#99FF99'],
#                 text=anomaly_percentages,
#                 textposition='auto',
#             )
#         ])
        
#         fig.update_layout(
#             title="Pourcentage de n≈ìuds anormaux par type (IsolationForest + Unidimensionnel)",
#             xaxis_title="Type de n≈ìud",
#             yaxis_title="Pourcentage d'anomalies (%)",
#             yaxis=dict(range=[0, 100]),
#             height=350,
#         )
        
#         st.plotly_chart(fig, use_container_width=True)
    
#     with col2:
#         # Graphique √† barres horizontales des m√©tiques affect√©es
#         metrics = ['avg_dns_time', 'std_dns_time', 'avg_score_scoring', 
#                   'std_score_scoring', 'avg_latence_scoring', 'std_latence_scoring']
        
#         # Noms plus lisibles pour l'affichage
#         display_names = [
#             'Temps DNS moyen', 
#             '√âcart-type DNS', 
#             'Score scoring moyen', 
#             '√âcart-type scoring', 
#             'Latence scoring moyenne', 
#             '√âcart-type latence'
#         ]
        
#         # Compter le nombre d'anomalies par m√©trique
#         anomaly_counts = [0] * len(metrics)
#         threshold_p_val = st.session_state.p_value_threshold / 100
        
#         for i, metric in enumerate(metrics):
#             p_val_col = f'p_val_{metric}'
            
#             for node_type in ["boucles", "peag_nro", "olt"]:
#                 if st.session_state.results[node_type] is not None and p_val_col in st.session_state.results[node_type].columns:
#                     anomaly_counts[i] += (st.session_state.results[node_type][p_val_col] < threshold_p_val).sum()
        
#         colors = ['#FF9999', '#66B3FF', '#99FF99', '#FFCC99', '#C2C2F0', '#FFB3E6']
        
#         fig = go.Figure()
        
#         fig.add_trace(go.Bar(
#             y=display_names,
#             x=anomaly_counts,
#             orientation='h',
#             marker_color=colors,
#             text=anomaly_counts,
#             textposition='auto',
#         ))
        
#         fig.update_layout(
#             title="Nombre d'anomalies par m√©trique (d√©tection unidimensionnelle)",
#             xaxis_title="Nombre d'anomalies",
#             yaxis=dict(
#                 categoryorder='total ascending',
#             ),
#             height=350,
#         )
        
#         st.plotly_chart(fig, use_container_width=True)

# Fonction pour cr√©er un graphique 3D pour l'approche unidimensionnelle
def create_3d_plot(test_name, variables_test):
    row_to_plot = st.session_state.lignes_1fev[st.session_state.lignes_1fev['name'] == test_name]
    
    # Axes x et y (distribution empirique)
    x = np.array(st.session_state.dict_distribution_test[variables_test[0]][test_name])
    y = np.array(st.session_state.dict_distribution_test[variables_test[1]][test_name])
    
    # Bornes de la grille
    xmin, xmax = x.min(), x.max()
    ymin, ymax = y.min(), y.max()
    
    # Grille 2D (100x100 points)
    X, Y = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]
    positions = np.vstack([X.ravel(), Y.ravel()])
    
    # Estimation densit√© empirique avec gaussian_kde
    values = np.vstack([x, y])
    kernel = gaussian_kde(values)
    Z = np.reshape(kernel(positions).T, X.shape)
    
    x_point = float(row_to_plot[variables_test[0]])
    y_point = float(row_to_plot[variables_test[1]])
    
    # Calculer la densit√© √† ce point pr√©cis
    point_position = np.array([[x_point], [y_point]])
    z_point = float(kernel(point_position))
    
    # Figure 3D
    fig = go.Figure(data=[go.Surface(x=X, y=Y, z=Z, colorscale='Plasma')])
    fig.update_layout(
        title=f'Distribution Empirique 3D de {test_name}',
        scene=dict(
            xaxis_title=variables_test[0],
            yaxis_title=variables_test[1],
            zaxis_title='Densit√©'
        ),
        width=900,
        height=700,
        margin=dict(l=0, r=0, b=0, t=30)
    )
    
    # Marqueur pour le point actuel
    is_anomaly = z_point < 0.05
    text = "Anomalie" if is_anomaly else ""
    marker_color = 'red' if is_anomaly else 'green'
    
    fig.add_trace(go.Scatter3d(
        x=[x_point],
        y=[y_point],
        z=[z_point + 0.05],  # L√©g√®rement au-dessus pour la visibilit√©
        mode='markers+text',
        text=[text],
        marker=dict(size=8, color=marker_color),
        textposition="top center"
    ))
    
    return fig

# Fonction pour ex√©cuter la d√©tection d'anomalies
def run_anomaly_detection():
    # Instance de classe : recherche les noeuds anormaux
    nc = NodesChecker()
    
    # Calcul des p_values √† partir des distributions empiriques
    lignes_1fev_with_pval = NodesChecker.add_p_values(
        st.session_state.lignes_1fev.copy(), 
        st.session_state.dict_distribution_test
    )

    # Application de l'isolation forest
    lignes_1fev_with_if_scores = st.session_state.isolation_forest.predict(st.session_state.lignes_1fev)
    st.session_state.df_with_anomalies = lignes_1fev_with_if_scores
    
    # Boucles
    # p values
    df_p_values_boucle = nc.get_df_fisher_p_values(
        lignes_1fev_with_pval,
        node_type='boucle',
        p_values=st.session_state.p_values_col
    )
    # scores d'isolation forest
    df_if_scores_boucle = nc.get_if_scores_by_node(lignes_1fev_with_if_scores, node_type='boucle')
    df_results_boucle = pd.merge(df_p_values_boucle, 
                                  df_if_scores_boucle[['avg_isolation_forest_score', 
                                                       'majority_anomaly_score',
                                                       'anomaly_percentage',
                                                       'total_samples',
                                                       'anomaly_count']], 
                                  how='left', 
                                  left_index=True, right_index=True)

    st.session_state.results["boucles"] = df_results_boucle
    
    # Filtrer les boucles d√©faillantes
    boucles_defaillantes = df_results_boucle[df_results_boucle['avg_isolation_forest_score'] < st.session_state.isolation_forest_threshold].index
    
    if len(boucles_defaillantes) > 0:
        lignes_1fev_with_pval = lignes_1fev_with_pval[~lignes_1fev_with_pval['boucle'].isin(boucles_defaillantes)]
        lignes_1fev_with_if_scores = lignes_1fev_with_if_scores[~lignes_1fev_with_if_scores['boucle'].isin(boucles_defaillantes)]
    
    # PEAG
    # p values
    df_p_values_peag = nc.get_df_fisher_p_values(
        lignes_1fev_with_pval,
        node_type='peag_nro',
        p_values=st.session_state.p_values_col
    )
    # scores d'isolation forest
    df_if_scores_peag = nc.get_if_scores_by_node(lignes_1fev_with_if_scores, node_type='peag_nro')
    df_results_peag = pd.merge(df_p_values_peag, 
                                  df_if_scores_peag[['avg_isolation_forest_score', 
                                                       'majority_anomaly_score',
                                                       'anomaly_percentage',
                                                       'total_samples',
                                                       'anomaly_count']], 
                                  how='left', 
                                  left_index=True, right_index=True)
    st.session_state.results["peag_nro"] = df_results_peag
    
    # Filtrer les PEAG d√©faillants
    peag_defaillants = df_results_peag[df_results_peag['avg_isolation_forest_score'] < st.session_state.isolation_forest_threshold].index
   
    if len(peag_defaillants) > 0:
        lignes_1fev_with_pval = lignes_1fev_with_pval[~lignes_1fev_with_pval['peag_nro'].isin(peag_defaillants)]
        lignes_1fev_with_if_scores = lignes_1fev_with_if_scores[~lignes_1fev_with_if_scores['peag_nro'].isin(peag_defaillants)]
    
    # OLT
    # p values
    df_p_values_olt = nc.get_df_fisher_p_values(
        lignes_1fev_with_pval,
        node_type='olt_name',
        p_values=st.session_state.p_values_col
    )
    # scores d'isolation forest
    df_if_scores_olt = nc.get_if_scores_by_node(lignes_1fev_with_if_scores, node_type='olt_name')
    df_results_olt = pd.merge(df_p_values_olt, 
                                  df_if_scores_olt[['avg_isolation_forest_score', 
                                                       'majority_anomaly_score',
                                                       'anomaly_percentage',
                                                       'total_samples',
                                                       'anomaly_count']], 
                                  how='left', 
                                  left_index=True, right_index=True)
    st.session_state.results["olt"] = df_results_olt

# Main pour organisation de l'interface
def main():
    # Initialiser l'√©tat de session
    initialize_session_state()
    
    # Afficher l'en-t√™te
    show_header()
    
    # Cr√©er le menu de navigation horizontal - nouvel ordre
    menu = ["üìä Tableau de bord", "‚öôÔ∏è Configuration et d√©tection", "üìà R√©sultats", "üîß Insertion d'anomalies (Optionnel)", "‚ùì Aide"]
    choice = st.radio("Navigation", menu, horizontal=True)
    
    st.markdown("---")
    
    # Afficher la page correspondante au choix
    if choice == "üìä Tableau de bord":
        show_home()
    elif choice == "‚öôÔ∏è Configuration et d√©tection":
        show_detection_config()
    elif choice == "üìà R√©sultats":
        show_results()
    elif choice == "üîß Insertion d'anomalies (Optionnel)":
        show_anomaly_insertion()
    elif choice == "‚ùì Aide":
        show_help()

if __name__ == "__main__":
    main()